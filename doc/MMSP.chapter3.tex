% MMSP.chapter3.tex

\chapter{\MMSP\ tutorials}
The following sections present a few short tutorials on writing, compiling, and running simple \MMSP\ programs.  For those totally confused by the syntax of the examples presented here we suggest consulting an introductory {\tt c++} text first.

\section{A quick tutorial}
\subsection{The {\tt Hello MMSP!} program}
Because every good programming language or interface tutorial starts with a ``Hello World!'' example program, we'll do the same.  For most \MMSP\ applications, we include a header file named {\tt MMSP.hpp}.  Then we need a {\tt main()} program and a few lines to print out our message.  Here it is:
\begin{shadebox}
\begin{verbatim}
    #include"MMSP.hpp"

    int main(int argc, char* argv[])
    {
        MMSP::Init(argc,argv);

        std::cout<<"Hello MMSP!"<<std::endl;

        MMSP::Finalize();
        
        return 0;
    }
\end{verbatim}
\end{shadebox}
The only code here that should look out of the ordinary are the statements
\begin{shadebox}
\begin{verbatim}
    MMSP::Init(argc,argv);
\end{verbatim}
\end{shadebox}
and
\begin{shadebox}
\begin{verbatim}
    MMSP::Finalize();
\end{verbatim}
\end{shadebox}
What do these lines do?  For single processor programs, they do absolutely nothing -- they could actually be removed without any consequences.  However, for programs that use the message passing interface (MPI), they act as wrappers for the similarly named {\tt MPI_Init} and {\tt MPI_Finalize} commands.  It's useful to include them here because they'll allow us to write programs that may be compiled for both single or multiple processor environments.

Programmers familiar with {\tt c++} will notice that there's obviously some \MMSP\ namespace being used here.  For those less familiar, namespaces are a somewhat recent addition to {\tt c++} that are used as a means of avoiding naming conflicts.  We can avoid using namespace resolution so frequently if we use an appropriate {\tt using} statement, i.e. 
\begin{shadebox}
\begin{verbatim}
    #include"MMSP.hpp"
    using namespace MMSP;

    int main(int argc, char* argv[])
    {
        Init(argc,argv);
\end{verbatim}
\end{shadebox}
Namespaces serve to prevent programming errors and to ensure code reusability, so naturally we should apply {\tt using} statements with care.  In the examples that follow, we'll sometimes assume a {\tt using} statement has been issued for the sake of brevity.

The observant reader may notice that we've used some of the stream input/output functions of {\tt c++} without including the requisite {\tt <iostream>} header.  In fact, this header and many other standard {\tt c++} headers are included implicitly thorough the file {\tt MMSP.hpp}.  If you need a particular standard header for your application and aren't sure if it has been included by {\tt MMSP.hpp}, you can always just {\tt \#include} it in your source code without any ill effects.

So that's it as far as the code goes.  This is a source file that may be compiled for both single and parallel simulations of... nothing.  In a moment we will move on to code that actually does something, but for now we should say a few words about compiling the code and running the executable.

\subsection{Compiling and running {\tt Hello MMSP!}}
Compiling code is a task that is, unfortunately, fairly platform dependent.  While \MMSP\ programs should compile easily on any platform, the required steps to do so may not look like the method shown here.  That said, let's look at how we would compile the previous example for a typical Linux or Unix setup.  Suppose the above code has been saved to a file named {\tt hello.cpp}, and that \MMSP\ has been extracted to the same directory.  A typical Linux machine will have at the least the GNU family of compilers installed, in which case we would type the command 
\begin{shadebox}
\begin{verbatim}
    g++ -I MMSP/include hello.cpp -o hello
\end{verbatim}
\end{shadebox}
which produces an executable file named {\tt hello}.  The compiler option {\tt -I ...} suggests a directory to search for non-standard headers; if your \MMSP\ headers reside somewhere else, you'll need to make the appropriate change.  To run the program, we type
\begin{shadebox}
\begin{verbatim}
    ./hello
\end{verbatim}
\end{shadebox}
which should produce our message.  Many other compilers on Linux and Unix machines use the same options as listed here, so this line may be very close to what you might use, even if you're not using {\tt g++}.

Now let's move on to parallel compilation.  We assume that if you're not skipping over this part, you have the MPI libraries installed on your machine (as well as your cluster).  With a typical MPI installation, a number of programs are included which effectively wrap your usual {\tt c++} compiler with a script named something like {\tt mpic++}, {\tt mpicxx}, {\tt mpicc}, etc.  With this in mind, we issue a command which may look like
\begin{shadebox}
\begin{verbatim}
    mpicxx -I MMSP/include -include mpi.h hello.cpp -o hello
\end{verbatim}
\end{shadebox}
which again produces an executable named {\tt hello}.  This time, however, we need to run {\tt hello} using an MPI command such as {\tt mpirun} or {\tt mpiexec} (see the documentation for your MPI distribution),
\begin{shadebox}
\begin{verbatim}
    mpirun -np 4 hello
\end{verbatim}
\end{shadebox}
which in this case produces our message four times.  The author sincerely hopes that your experience is this straightforward, but don't count on it!

\section{A {\tt grid} class example}
In this section, we look at an example that uses the \MMSP\ {\tt grid} template class, and actually resembles part of a program you might actually use:
\begin{shadebox}
\begin{verbatim}
    #include"MMSP.hpp"
    using namespace MMSP;

    int main(int argc, char* argv[])
    {
        Init(argc,argv);

        grid<2,int> GRID(1,0,100,0,100);

        for (int x=x0(GRID); x<x1(GRID); x++)
            for (int y=y0(GRID); y<y1(GRID); y++)
                GRID[x][y] = GRID[x+1][y]-GRID[x-1][y];

        output(GRID,"testgrid");

        Finalize();
    }
\end{verbatim}
\end{shadebox}
To compile, issue
\begin{shadebox}
\begin{verbatim}
    g++ -I MMSP/include grid_example.cpp -o grid_example -lz
\end{verbatim}
\end{shadebox}
This program performs the amazing feat of generating a new 2-dimensional {\tt grid} object, assigning to each node the sum of {\tt x} and {\tt y}, and then writing the final state of the {\tt grid} to a file, the name of which is simply {\tt testgrid}.  Of course this isn't really anything special, but the imaginative reader may begin to see how this program might be used as a template to generate other, more useful {\tt grid} objects.

Several new features have been introduced in this example.  First, the line
\begin{shadebox}
\begin{verbatim}
    grid<2,int> GRID(1,0,100,0,100);
\end{verbatim}
\end{shadebox}
constructs the {\tt grid} object.  Objects of the {\tt grid} class take two template arguments (those arguments within {\tt < >}), the first being the dimension ({\tt 2}) and the second being the data type ({\tt int}).  In {\tt MMSP}, the dimension of a {\tt grid} can be any (constant) integer greater than zero, while the data type can be any of {\tt c++}'s built-in types or any of the \MMSP\ data types (to be discussed later).  In other words, \MMSP\ allows for simulations in arbitrary spatial dimensions, and the type of data stored at each {\tt grid} point is quite flexible.

The name of the {\tt grid} comes next, which in this case is ({\tt GRID}), and is followed by constructor arguments in parentheses.  These arguments indicate the total number of fields to create at each node (relevant only for vector-like data types) and the lower and upper limits in the {\tt x} and {\tt y} directions, respectively.  Like for {\tt c++} arrays, lower {\tt grid} limits are inclusive and upper limits are exclusive, so in this case we have that $0\leq x,y<100$, and a total number of $100$ nodes along each coordinate axis.  Unlike {\tt c++} arrays, the limits may be either positive or negative, as long as the upper limit is always larger than the lower limit.  Note that these limits are the {\em global} limits; they define the size of the entire {\tt grid} object.  The portion of a {\tt grid} that is actually stored on a given machine is usually smaller than this in parallel programs.

To give a sense of how the above generalizes to other dimensions and data types, consider the following:
\begin{shadebox}
\begin{verbatim}
    grid<3,double> GRID(1,0,128,0,256,0,256);
\end{verbatim}
\end{shadebox}
This statement declares a 3-dimensional {\tt grid} object with $0\leq x<128$, $0\leq y<256$, $0\leq z<256$, and storage for the built-in data type {\tt double} at each node.

Returning to the example code, the next lines iterate through the nodes of the {\tt grid},
\begin{shadebox}
\begin{verbatim}
    for (int x=x0(GRID); x<x1(GRID); x++)
        for (int y=y0(GRID); y<y1(GRID); y++)
\end{verbatim}
\end{shadebox}
The functions {\tt x0}, {\tt x1} and {\tt y0}, {\tt y1} have been invoked to retrieve the {\em local} limits in each direction.  As suggested above, the local grid size in a parallel program is typically smaller than the global grid size because parallelization in \MMSP\ is achieved through spatial decomposition.  Use of these functions ensures that we iterate only through the nodes stored by the local process.  While it isn't strictly necessary to use these functions in code meant to be run on a single processor, using them now will make parallelization completely trivial.

The line
\begin{shadebox}
\begin{verbatim}
    GRID[x][y] = GRID[x+1][y]-GRID[x-1][y];
\end{verbatim}
\end{shadebox}
uses subscript operators {\tt [ ]} to set and retrieve data stored at nodes of the {\tt grid}.  The usage of the subscript operator should look familiar to anyone who has programmed in {\tt c}-style languages, and it has the expected effect -- the subscript operator works the same way for \MMSP\ grid objects as it does for subscripted arrays.  However, we will later see that the \MMSP\ subscript operators are ``smarter'' in the sense that they're cognizant of boundary conditions and adjust appropriately for calls made to nodes that are out of bounds.  There are also more advanced ways to access {\tt grid} data which we will discuss later.

Finally, the line 
\begin{shadebox}
\begin{verbatim}
    output(GRID,"testgrid");
\end{verbatim}
\end{shadebox}
seems fairly self-explanatory, and it is.  This function passes the data contained in the {\tt grid} class through {\tt zlib} and writes the compressed data to a file; this requires the flag {\tt -lz} appended to the compiler command.  Here we also note that in the case of a parallel program, the {\tt output} function performs the additional task of piecing back together the global {\tt grid} object from all local {\tt grid} objects before writing to a file.

As a point of reference, let's now look at how we might do something similar to the example above with the usual {\tt c} or {\tt c++} subscripted arrays:
\begin{shadebox}
\begin{verbatim}
    int main(int argc, char* argv[])
    {
        int GRID[100][100];

        for (int x=0; x<100; x++)
            for (int y=0; y<100; y++)
                GRID[x][y] = GRID[x+1][y]-GRID[x-1][y];

        // etc.
    }
\end{verbatim}
\end{shadebox}
This may look considerably simpler, but consider the following: how do we run this code as a parallel process?  The immediate answer is that we introduce MPI funtion calls, but then we also need to decide how to subdivide the grid, how to deal with boundary conditions, how to put the pieces back together when we're done, etc.  Then again, what if we want to change the number of processors or number of nodes in each direction and maintain an optimal subdivision scheme?  And what about boundary conditions?  As written, the code will attempt to access data that is out of the bounds of the array.  This will probably lead to runtime errors, or at least some unintentional results.  Additional code needs to be written to remedy this problem.  Starting from scratch, these operations all require a great deal of code development, whereas all of these are done by \MMSP\ automatically.


\section{More examples}
This section provides a number of additional examples demonstrating typical \MMSP\ operations.

\subsection{Accessing node data}
In the previous section, we saw how data within a {\tt grid} object may be accessed through the subscript operator, e.g.
\begin{shadebox}
\begin{verbatim}
    // assign some node of GRID2D to "value"
    double value = GRID2D[x][y];

    // assign "value" to some node of GRID3D 
    GRID3D[x][y][z] = value;
\end{verbatim}
\end{shadebox}
There are two other ways to access data, both of which may be useful depending on the context.  The first alternative is through integer subscripting using the parentheses operator {\tt ( )}, e.g.
\begin{shadebox}
\begin{verbatim}
    // assign the value of the ith node of GRID2D to "value"
    double value = GRID2D(i);

    // assign "value" as the value of the ith node of GRID3D
    GRID3D(i) = value;
\end{verbatim}
\end{shadebox}
How is this operator useful?  The answer is that it allows us to write code that works nicely for {\tt grid} objects of arbitrary dimension:
\begin{shadebox}
\begin{verbatim}
    for (int i=0; i<nodes(GRID); i++) GRID(i) = ... ;
\end{verbatim}
\end{shadebox}
Here, the function {\tt nodes} tells us how many nodes\footnote{The {\tt nodes} function does not count ``ghost'' cells when such exist.  This is not a problem because the parentheses operator skips these nodes anyway.} of the {\tt grid} object are stored locally, so that we can simply iterate through them with a single loop.  If we perform the same operations with each node regardless of dimension, then our code can be reused without adding additional loops, subscript operators, etc.

The second alternative is through {\tt vector}-based subscripting.  In this case, an {\tt MMSP::vector} object is used:
\begin{shadebox}
\begin{verbatim}
    MMSP::grid<2,double> GRID(1,0,100,0,100);
    ...

    for (int i=0; i<nodes(GRID); i++) {
        MMSP::vector<int> x = MMSP::position(GRID,i);
        GRID(x) = ... ;
    }
\end{verbatim}
\end{shadebox}
This example shows the declaration of an {\tt MMSP::vector} object, and its assignment to the coordinates of the $i^\text{th}$ node of the {\tt grid}.  How might this be useful?  Suppose we needed to perform some operation on all the nearest neighbors of a given node.  With {\tt vector}-based subscripting, we can use {\tt vector} addition to make quick work of the problem,
\begin{shadebox}
\begin{verbatim}
    for (int i=0; i<nodes(GRID); i++) {
        MMSP::vector<int> x = MMSP::position(GRID,i);

        for (int j=0; j<dim; j++) {
            MMSP::vector<int> dx(dim,0);
            dx[j] =  1;

            GRID(x+dx) = ... ;
            GRID(x-dx) = ... ;
        }
    }
\end{verbatim}
\end{shadebox}
While this kind of operation could be handled quite easily with the more traditional subscript operator, note that this code would be much easier to extend to any number of spatial dimensions.

\subsection{File input and output}
Input and output of {\tt grid} data to a file are performed as follows:
\begin{shadebox}
\begin{verbatim}
    const char* filename = "...";
    grid<2,double> GRID(1,0,100,0,100);

    // Input grid from file
    input(GRID,filename);

    // Output grid to file
    output(GRID,filename);
\end{verbatim}
\end{shadebox}
Note that the second argument to the {\tt input} and {\tt output} functions is a character array of type {\tt char*}.  Error checking does occur when a {\tt grid} is input from a file; attempts to input a {\tt grid} of the wrong dimension or data type will cause \MMSP\ to produce a error message and exit the code.

To be sure, there's probably only rare occasions when we want to use {\tt input} to overwrite an existing {\tt grid}.  Quite often, though, we want to create a new {\tt grid} object from {\tt grid} data contained within a file.  In this case, we use the {\tt grid} constructor,
\begin{shadebox}
\begin{verbatim}
    const char* filename = "...";
    grid<2,double> GRID(filename);
\end{verbatim}
\end{shadebox}
which reads {\tt grid} data from the specified file and uses it to construct the {\tt grid} object.

In a later chapter, we discuss the {\tt grid} class in more detail, and in particular, we note that most functions operating on a {\tt grid} can be called in two ways.  This also applies here,
\begin{shadebox}
\begin{verbatim}
    // One way to output a grid...
    output(GRID,filename);

    // ... and an equivalent way.
    GRID.output(filename);
\end{verbatim}
\end{shadebox}
The first case uses typical {\tt C} style syntax, while the second case uses the class member function syntax of {\tt C++}.  For now, note that almost all functions that operate on the {\tt grid} class or other \MMSP\ data classes may be called both ways.

In case you were wondering, all of the code shown above can be used in a parallel program.  In this case, the functions {\tt input} and {\tt output} automatically coordinate I/O tasks over all processors.  The {\tt grid} constructor and the {\tt input} function also perform the task of determining the optimal\footnote{``Optimal'' here means that the subdivision is chosen such that it will produce the fewest number of ghost cells possible, while maintaining as evenly balanced a load as possible.} {\tt grid} subdivision scheme.  


\subsection{Boundary conditions}
Boundary conditions in \MMSP\ are handled automatically.  To show what this means, consider the following:
\begin{shadebox}
\begin{verbatim}
    grid<2,double> f(1,0,100,0,100);

    for (int x=x0(f); x<x1(f); x++)
        for (int y=y0(f); y<y1(f); y++) {
            double dfdx = (f[x+1][y]-f[x-1][y])/(2.0*dx(f));
            ...
        }
\end{verbatim}
\end{shadebox}
This code traverses each node in the {\tt grid}, computing the derivative along the $x$ axis, among a number of other possible operations.  This is simple enough, but what happens at the {\tt grid} boundaries?  If similar code was written using built-in arrays, it would typically fail with a segmentation fault, and in any case, it certainly wouldn't produce the desired results.  However, with {\tt MMSP} {\tt grid} objects, this isn't a problem; all of the data access operators in \MMSP\ are cognizant of domain boundaries and always enforce the chosen boundary conditions.

For the code example above, periodic boundary conditions are used.  This is the default boundary condition in \MMSP.  A number of other boundary conditions are possible, including Dirichlet, Neumann, and mirror boundaries.  Parallel processor boundaries are another special type of boundary condition which is not explicitly set by the user.

To change the boundary conditions used for a {\tt grid}, one might use\footnote{Note, as usual, the boundary conditions and ``set'' functions all belong to namespace \MMSP\ and must be used in the absence of a {\tt using} statement.}
\begin{shadebox}
\begin{verbatim}
    grid<2,double> GRID(1,0,100,0,100);

    // set x-axis boundary conditions
    b0(GRID,0) = Dirichlet;         // BC at lower x-axis boundary
    b1(GRID,0) = mirror;            // BC at upper x-axis boundary

    // set y-axis boundary conditions
    b0(GRID,1) = periodic;          // BC at lower y-axis boundary
    b1(GRID,1) = periodic;          // BC at upper y-axis boundary
\end{verbatim}
\end{shadebox}
This example demonstrates that the boundary conditions may not only be set independently for each coordinate axis, but that it's also possible to independently set the conditions at the upper and lower boundaries (within reason).


\section{The prototypical \MMSP\ program}
\MMSP\ was created with the intent that it would be used for mesoscale microstructure simulation.  So let's look at how we would typically write code to do just that.
\begin{shadebox}
\begin{verbatim}
    // prototype.cpp
    #include"update.hpp"
    using namespace MMSP;

    int main(int argc, char* argv[])
    {
        Init(argc,argv);

        grid<2,double> GRID(argv[1]);

        update(GRID,atoi(argv[3]);

        output(GRID,argv[2]);

        Finalize();
    }
\end{verbatim}
\end{shadebox}
In this example, in addition to the usual \MMSP\ boilerplate code, we have a {\tt grid} constructor that reads from a file with a name specified by {\tt argv[1]}, a call to some function called {\tt update} (more on this in a moment), and a call to {\tt output} the {\tt grid} object to a file with a name specified by {\tt argv[2]}. After compiling this program, we would run it with the command line
\begin{shadebox}
\begin{verbatim}
    ./program initial.PF final.PF 100
\end{verbatim}
\end{shadebox}
or, if we compiled with the MPI libraries, we would run in with something similar to
\begin{shadebox}
\begin{verbatim}
    mpirun -np 4 program initial.PF final.PF 100
\end{verbatim}
\end{shadebox}
Here, $100$ is the intended number of time steps that the {\tt update} function will perform.

Now that we have our prototype {\tt main()} function, let's look at the {\tt update} function.  For this example, we would have a new header file named {\tt update.hpp},
\begin{shadebox}
\begin{verbatim}
    // update.hpp
    #include "MMSP.hpp"
    using namespace MMSP;

    void update(grid<2,double>& GRID, int steps)
    {
        grid<2,double> update(GRID);

        for (int step=0; step<steps; step++) {
            for (int x=x0(GRID); x<x1(GRID); x++)
                for (int y=y0(GRID); y<y1(GRID); y++) {
                    // replace this with a "real" computation...
                    update[x][y] = GRID[x][y];
                }

            swap(GRID,update);
            ghostswap(GRID);
        }
    }
\end{verbatim}
\end{shadebox}
Here we define the {\tt update} function, with its first argument a {\tt grid} object and its second argument the number of time steps to perform.  The only thing we should bring special attention to here is the use of the ampersand ({\tt \&}) to force call-by-reference, which overrides {\tt c++}'s usual convention of call-by-value (see a typical introductory text for more).

On the first line within the {\tt update} function, we create a new {\tt grid} object, itself called {\tt update}.  The new {\tt grid} is created using a constructor with {\tt GRID} as its argument.  What this does is it generates a {\tt grid} with the same spatial extent, number of fields, parallel topology, etc.  In other words, the {\tt grid} called {\tt update} is a suitable workspace to store the values of {\tt GRID} for the next time step as we compute them.

Next, we have a loop over all time steps.  Within this loop we iterate through the nodes of {\tt GRID} just as in the example of the previous section.  The limiting values of {\tt x} and {\tt y} are obtained by appropriate function calls.  At each node, we would normally perform some meaningful computation to determine the value of {\tt GRID} at the next time step, then store the value in {\tt update}.  Here we simply copy the value of {\tt GRID} at this node to {\tt update}.

After computations are performed at each node, we have two more operations.  First, we {\tt swap} the data of {\tt GRID} and {\tt update}.  {\tt GRID} now contains the new values, while {\tt update}, the workspace, contains the old.  Next, a function called {\tt ghostswap} is called with {\tt GRID} as its argument.  For single processor programs, the {\tt ghostswap} function does nothing.  For parallel programs, it performs a coordinated series of ``ghost'' cell data swaps, such that the ghosts associated with the local portion of {\tt GRID} are filled with the appropriate data from all neighboring processors.  And again, while it's not critical to include this line when our intent is to write a single processor program, it will serve us well to include it here because it will allow us to easily parallelize the code later.


\section{Application: the Allen-Cahn equation}
Now that we've seen much of the basic syntax used in \MMSP, let's apply it to a few realistic physical problems.  The first application we'll discuss is the numerical solution of the Allen-Cahn equation, which comes from a well-known model for order-disorder phase transformations in solids.  In this model, the state of the system is described by a single parameter, $\phi$, which represents the local atomic ordering.  Two distinct, stable variants are represented when $\phi=-1$ and $\phi=1$.  The energy density of the system includes a penalty for states other than these as well as a term that depends on the gradient of $\phi$.  The total energy of the system takes the form
\begin{equation}
F = \int_V -\frac{r}{2}\phi^2+\frac{u}{4}\phi^4+\frac{\kappa}{2}|\nabla \phi|^2\, dV
\end{equation}
where $r$, $u$, and $\kappa$ are phenomenological constants.  The time evolution of $\phi$ is assumed to take the form
\begin{equation}
\frac{d\phi}{dt} = -M\frac{\delta F}{\delta \phi} = -M(-r\phi+u\phi^3-\kappa\Delta \phi).
\end{equation}
Using a forward Euler time step, the above would be discretized as
\begin{equation}
\phi^{t+\Delta t} = \phi^t -\Delta t\, M(-r\phi^t+u(\phi^t)3-\kappa\Delta \phi^t).
\end{equation}

Now, let's look at an \MMSP\ code representation of the above.  Suppose we aim to write an {\tt update} function, similar to what was shown in the previous section.  This time, we'll additionally use the {\tt c++} template syntax to write a code that will work for {\tt grid} objects of any dimension (and any scalar data type):
\begin{shadebox}
\begin{verbatim}
template <int dim, typename T>
void update(MMSP::grid<dim,T>& grid, int steps)
{
    MMSP::grid<dim,T> update(grid);

    double r = 1.0;
    double u = 1.0;
    double K = 1.0;
    double M = 1.0;
    double dt = 0.01;

    for (int step=0; step<steps; step++) {
       for (int i=0; i<nodes(grid); i++) {
          double phi = grid(i);
          update(i) =
             phi-dt*M*(-r*phi+u*pow(phi,3)-K*laplacian(grid,i));
       }
       swap(grid,update);
       ghostswap(grid);
    }
}
\end{verbatim}
\end{shadebox}
The {\tt update} function declaration is equivalent to those shown before, although the use of template syntax affords us some greater generality.  A temporary {\tt grid} object called {\tt update} is declared next, again with template syntax.  The constants $r$, $u$, etc.\ are then declared and initialized.  The remainder of the code performs the desired time steps.  At each time step, the following computation is performed at each node:
\begin{shadebox}
\begin{verbatim}
double phi = grid(i);
update(i) = phi-dt*M*(-r*phi+u*pow(phi,3)-K*laplacian(grid,i));
\end{verbatim}
\end{shadebox}
The reader will notice that this looks nearly identical to the pseudocode given above.  Here, the {\tt c++} math library function {\tt pow} is used to compute $\phi^3$ and the {\tt grid} class {\tt laplacian} operator is used to compute $\Delta \phi$.

The Allen-Cahn equation is a fairly simple model, yet it demonstrates many of the powerful features that \MMSP\ offers.  Note that, with only a few unique lines of {\tt c++}, we have produced a code that
\begin{enumerate}
\item{Solves a realistic physical problem with minimal software development.}
\item{Works for {\tt grid}s of arbitrary spatial dimension.}
\item{Works for {\tt grid}s of arbitrary scalar data type.}
\item{Handles boundary conditions with no user intervention.}
\item{Produces both single processor and parallel code, depending only on compiler options.}
\item{Automatically produces an optimal parallel mesh topology, when required.}
\end{enumerate}


\section{Running the example codes}
Each example program in the {\tt MMSP/examples} directory contains at least three files: the {\tt example.hpp}, defining the {\tt generate} and {\tt update} functions; {\tt example.cpp}, defining the {\tt grid} types to be used; and a {\tt Makefile}, which helps to simplify compiling {\tt MMSP} code.  The {\tt hpp} and {\tt cpp} files should be self-explanatory, based on the preceding discussion.  A file named {\tt notes} may also be included, identifying key research papers used in developing the program.

Let's take a closer look at the {\tt Makefile} from the Allen-Cahn example code, available in {\tt MMSP/examples/phase\_transitions/allen-cahn/}:
\begin{shadebox}
\begin{verbatim}
# includes
incdir = ../../../include

# compilers/flags
compiler = g++
flags = -O3 -I $(incdir)
pcompiler = mpic++
pflags = -O3 -I $(incdir) -include mpi.h

# dependencies
core = $(incdir)/MMSP.main.hpp \
       $(incdir)/MMSP.utility.hpp \
       $(incdir)/MMSP.grid.hpp

# the program
allen-cahn: allen-cahn.cpp allen-cahn.hpp $(core)
	$(compiler) $(flags) $< -o $@ -lz

parallel: allen-cahn.cpp allen-cahn.hpp $(core)
	$(pcompiler) $(pflags) $< -o $@ -lz

clean:
	rm -f allen-cahn parallel
\end{verbatim}
\end{shadebox}
The purpose of this file is to specify the compiler and paths to any file required to build the code.  The folder {\tt ../../../include} specified in the first block equals {\tt MMSP/include}, where the core {\tt MMSP} header files are stored.  The second block specifies the compiler and relevant flags, including optimization level.  Options are set for both {\tt g++} and {\tt mpic++} here.  The last defninition block lists the specific {\tt MMSP} headers to be used in the program.  Note that not every header is included!

The blocks starting with {\tt allen-cahn:} and {\tt parallel:} specify the {\tt make} commands and their output.  Executing {\tt make allen-cahn} will build the executable {\tt allen-cahn} using {\tt g++}; {\tt make parallel} builds the executable {\tt parallel} using {\tt mpic++}.  Finally, executing {\tt make clean} will delete the executable files.

Any entry in the {\tt Makefile} can be modified.  For example, if you copy an example code as the basis for your own project, you can move it anywhere on your hard drive so long as you edit the {\tt incdir} variable appropriately.  You may also change the executable names and compiler flags at will.  The {\tt Makefile} is a powerful tool for keeping track of lengthy compiler commands.
